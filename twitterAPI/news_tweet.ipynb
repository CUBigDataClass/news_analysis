{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tweepy - Python library for accessing the Twitter API.\n",
    "import tweepy\n",
    "\n",
    "# TextBlob - Python library for processing textual data\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Pandas - Data manipulation and analysis library\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy - mathematical functions on multi-dimensional arrays and matrices\n",
    "import numpy as np\n",
    "\n",
    "# Regular Expression Python module\n",
    "import re\n",
    "\n",
    "import twitter_credentials\n",
    "import json\n",
    "import requests\n",
    "import datetime as DT\n",
    "\n",
    "import RAKE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://thinkinfi.com/automatic-keyword-extraction-using-rake-in-python/\n",
    "# !pip install python-rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT=\"https://big-data-news-analysis.es.us-central1.gcp.cloud.es.io:9243\"\n",
    "es = Elasticsearch(timeout=600,hosts=ENDPOINT,http_auth=('elastic', ''))\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API config\n",
    "twitterApiKey = twitter_credentials.CONSUMER_KEY\n",
    "twitterApiSecret = twitter_credentials.CONSUMER_SECRET\n",
    "twitterApiAccessToken = twitter_credentials.ACCESS_TOKEN\n",
    "twitterApiAccessTokenSecret = twitter_credentials.ACCESS_TOKEN_SECRET\n",
    "\n",
    "# Authenticate\n",
    "auth = tweepy.OAuthHandler(twitterApiKey,twitterApiSecret)\n",
    "auth.set_access_token(twitterApiAccessToken, twitterApiAccessTokenSecret)\n",
    "twetterApi = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "rake_object = RAKE.Rake(stopwords)\n",
    "\n",
    "keywords = ['officials issued citations', 'coronavirus violations overnight', 'ohio investigative unit']\n",
    "\n",
    "APIKEY=\"\"\n",
    "url = ('https://newsapi.org/v2/top-headlines?country=us&category=business&'\n",
    "       'apiKey='+APIKEY)\n",
    "\n",
    "response = requests.get(url)\n",
    "# issue: need to remove duplicates\n",
    "search_keys = []\n",
    "search_indices = []\n",
    "for k in response.json()['articles']:\n",
    "    if k['description'] != None:\n",
    "        keywords_pre = rake_object.run(k['description'][:-1]+k['title'],maxWords=5,minFrequency=1)\n",
    "        keywords = list(map(lambda x: x[0],keywords_pre))[:3]\n",
    "        index = '-'.join(keywords).replace(' ', '-')\n",
    "        search_indices.append(index)\n",
    "        keywords_or = '\\\"'+'\\\" OR \\\"'.join(keywords)+'\\\"'\n",
    "        search_keys.append(keywords_or)\n",
    "        res1 = es.index(index='news_v2',id=index,body=k)\n",
    "for i in search_keys[7:]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(data):\n",
    "    if data.get(\"extended_tweet\")!=None:\n",
    "        return data.get(\"extended_tweet\").get(\"full_text\") \n",
    "    elif data.get(\"retweeted_status\") != None:\n",
    "        if data.get(\"retweeted_status\").get(\"extended_tweet\") !=None:\n",
    "            return data.get(\"retweeted_status\").get(\"extended_tweet\").get(\"full_text\") \n",
    "        else:\n",
    "            return data.get(\"retweeted_status\").get(\"text\") \n",
    "    else:\n",
    "        return data.get(\"text\") \n",
    "\n",
    "\n",
    "for idx,keywords in enumerate(search_keys):\n",
    "    test=keywords\n",
    "    date_since = str(DT.date.today()-DT.timedelta(days=14))\n",
    "    print(keywords)\n",
    "    tweets = tweepy.Cursor(twetterApi.search,\n",
    "                  q=keywords,\n",
    "                  lang=\"en\",\n",
    "                  since=date_since).items(2000)\n",
    "    index = search_indices[idx]\n",
    "    for t in tweets:\n",
    "        try:\n",
    "            data=t._json\n",
    "            text = get_text(data)\n",
    "            data_clean = {\n",
    "                'news_id':index,\n",
    "                \"created_at\":data.get(\"created_at\"),\n",
    "                'text':text,\n",
    "                'sentiment': model(text)\n",
    "            }\n",
    "            res = es.index(index='tweets_v2',id=data[\"id\"],body=data_clean)\n",
    "        except BaseException as e:\n",
    "            print(data)\n",
    "            print(\"Error on_data %s\" % str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
